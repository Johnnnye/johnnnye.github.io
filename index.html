<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>John Emslie â€“ Sound Designer & Composer</title>

  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css">
</head>
<body>

<main class="container" id="app">

  <section class="hero">
    <h1 id="about-trigger">John Emslie</h1>
    <p class="role">Sound Designer & Composer</p>
  </section>

  <section class="categories">
    <div class="node picture-node" data-note="146.83" data-pan="-0.4" style="top:32%; left:30%;">
      <span class="dot"></span><span class="label">Picture</span>
    </div>
    <div class="node" data-note="174.61" data-pan="0.35" style="top:50%; left:62%;">
      <span class="dot"></span><span class="label">Music</span>
    </div>
    <div class="node" data-note="196.00" data-pan="-0.15" style="top:68%; left:40%;">
      <span class="dot"></span><span class="label">Redesigns</span>
    </div>
    <div class="node" data-note="220.00" data-pan="0.2" style="top:78%; left:58%;">
      <span class="dot"></span><span class="label">Games</span>
    </div>
  </section>

  <footer class="contact">
    <a href="mailto:john@youremail.com" id="contact-email">Contact</a>
  </footer>

  <!-- ABOUT OVERLAY -->
  <div class="overlay hidden" id="about-overlay">
    <div class="overlay-content">
      <p>
        I work with sound as texture, space, and motion.<br><br>
        My focus is on interaction, restraint, and emotional clarity
        across games, picture, and experimental work.
      </p>
      <button class="close" id="about-close">Close</button>
    </div>
  </div>

</main>

<!-- PICTURE OVERLAY -->
<div class="picture-overlay hidden" id="picture-overlay">
  <button class="picture-close" id="picture-close">Ã—</button>

  <div class="picture-track">

    <div class="picture-project">
      <div class="project-text">
        <strong>Project Title</strong><br>
        Sound design and music for picture.<br>
        Short description goes here.
      </div>

      <div class="project-video">
        <iframe
          src="https://player.vimeo.com/video/892530565"
          allow="autoplay; fullscreen; picture-in-picture"
          allowfullscreen>
        </iframe>
      </div>
    </div>

  </div>
</div>

<script>
/* =========================
   AUDIO CORE
========================= */

let ctx, master, reverb;
let voices = [];
let audioStarted = false;

let breathNoise, breathGain, breathFilter;
let breathStartTime;
let breathDuration = 8000;

let contactOsc, contactGain;

const titleEl = document.getElementById("about-trigger");
const emailEl = document.getElementById("contact-email");

/* ðŸ”“ ONE-TIME AUDIO UNLOCK */
function unlockAudioOnce() {
  if (!ctx) initAudio();
  if (ctx.state === "suspended") ctx.resume();
  document.removeEventListener("click", unlockAudioOnce);
}
document.addEventListener("click", unlockAudioOnce, { once: true });

function initAudio() {
  if (audioStarted) return;

  ctx = new (window.AudioContext || window.webkitAudioContext)();

  master = ctx.createGain();
  master.gain.value = 0.9;
  master.connect(ctx.destination);

  reverb = ctx.createConvolver();
  const ir = ctx.createBuffer(2, ctx.sampleRate * 2, ctx.sampleRate);
  for (let c = 0; c < 2; c++) {
    const d = ir.getChannelData(c);
    for (let i = 0; i < d.length; i++) {
      d[i] = (Math.random() * 2 - 1) * Math.exp(-i / (ctx.sampleRate * 0.45));
    }
  }
  reverb.buffer = ir;

  const revGain = ctx.createGain();
  revGain.gain.value = 0.35;
  reverb.connect(revGain);
  revGain.connect(master);

  document.querySelectorAll(".node").forEach(el => {
    const freq = parseFloat(el.dataset.note);
    const panVal = parseFloat(el.dataset.pan);

    const baseGain = ctx.createGain();
    const focusGain = ctx.createGain();
    const pan = ctx.createStereoPanner();
    const osc = ctx.createOscillator();
    const focusOsc = ctx.createOscillator();

    baseGain.gain.value = 0;
    focusGain.gain.value = 0;
    pan.pan.value = panVal;

    osc.type = "sine";
    focusOsc.type = "sine";
    osc.frequency.value = freq;
    focusOsc.frequency.value = freq * 2;

    osc.connect(baseGain);
    focusOsc.connect(focusGain);
    baseGain.connect(pan);
    focusGain.connect(pan);
    pan.connect(master);
    pan.connect(reverb);

    osc.start();
    focusOsc.start();

    voices.push({ el, baseGain, focusGain });
  });

  initBreath();
  initContactTone();
  audioStarted = true;
}

/* ===== BREATH ===== */

function initBreath() {
  const buffer = ctx.createBuffer(1, ctx.sampleRate * 2, ctx.sampleRate);
  const data = buffer.getChannelData(0);
  for (let i = 0; i < data.length; i++) data[i] = Math.random() * 2 - 1;

  breathNoise = ctx.createBufferSource();
  breathNoise.buffer = buffer;
  breathNoise.loop = true;

  breathFilter = ctx.createBiquadFilter();
  breathFilter.type = "bandpass";
  breathFilter.frequency.value = 600;
  breathFilter.Q.value = 0.45;

  breathGain = ctx.createGain();
  breathGain.gain.value = 0;

  breathNoise.connect(breathFilter);
  breathFilter.connect(breathGain);
  breathGain.connect(reverb);
  breathNoise.start();

  const styles = getComputedStyle(titleEl);
  breathDuration = parseFloat(styles.animationDuration || "8") * 1000;
  breathStartTime = performance.now();
  requestAnimationFrame(breathLoop);
}

function breathLoop(now) {
  if (!audioStarted) return;
  const phase = ((now - breathStartTime) % breathDuration) / breathDuration;
  const amp = Math.sin(phase * Math.PI);
  breathGain.gain.setTargetAtTime(amp * 0.28, ctx.currentTime, 0.12);
  requestAnimationFrame(breathLoop);
